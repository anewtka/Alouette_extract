{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180d0595",
   "metadata": {},
   "source": [
    "# Process Subdirectories II\n",
    "\n",
    "#### Updated: Jan 13, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63f384",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39304129",
   "metadata": {},
   "source": [
    "Run for continuous processing of subdirectories, concurrent with the downloading of subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5f40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e6163cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628732b",
   "metadata": {},
   "source": [
    "Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83835627",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'Rav'\n",
    "process_on_VDI = True\n",
    "wait = 2 #in minutes\n",
    "stop_loop_threshold = 2640 #max while loops to prevent infinite loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9697506",
   "metadata": {},
   "source": [
    "Set directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42031944",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir_local = 'C:/Users/rnaidoo/Documents/Projects_data/Alouette_I/' #C: is not persistent on VDI\n",
    "rootDir_L = 'L:/DATA/Alouette_I/'\n",
    "downloadedDir = rootDir_local + '02_downloaded/'\n",
    "processingDir = rootDir_local + '03_processing/'\n",
    "result_localDir = rootDir_local + '05a_result_local/'\n",
    "if process_on_VDI:\n",
    "    processedDir = rootDir_L + '04_processed/' \n",
    "    unprocessedDir = rootDir_L + '04a_unprocessed/'\n",
    "    resultDir = rootDir_L + '05_result/' \n",
    "    logDir = rootDir_L + '06_log/'\n",
    "    move_to_L = True\n",
    "else:\n",
    "    processedDir = rootDir_local + '04_processed/' \n",
    "    unprocessedDir = rootDir_local + '04a_unprocessed/' \n",
    "    resultDir = rootDir_local + '05_result/' \n",
    "    logDir = rootDir_local + '06_log/'\n",
    "    move_to_L = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8b145",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86ad74",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0ef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(old_dir, new_dir, roll, subdir, copy_to_other_drive=False):\n",
    "    oldDir = old_dir + roll + '/' + subdir + '/'\n",
    "    newDir = new_dir + roll + '/' + subdir + '/'\n",
    "    os.makedirs(newDir, exist_ok=True)\n",
    "    \n",
    "    if copy_to_other_drive:\n",
    "        for file in os.listdir(oldDir):\n",
    "            shutil.copyfile(oldDir+file, newDir+file)\n",
    "    else:\n",
    "        for file in os.listdir(oldDir):\n",
    "            os.rename(oldDir+file, newDir+file)\n",
    "    \n",
    "    shutil.rmtree(old_dir + roll + '/' + subdir + '/')\n",
    "    if len(os.listdir(old_dir + roll + '/')) == 0:\n",
    "        shutil.rmtree(old_dir + roll + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdd51f",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4d331",
   "metadata": {},
   "source": [
    "#### Check if any subdirectories are waiting to be processed, then process them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3e898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_condition = False\n",
    "stop_condition_counter = 0\n",
    "\n",
    "while stop_condition == False:\n",
    "    if len(os.listdir(downloadedDir)) > 0:\n",
    "        for roll in os.listdir(downloadedDir):\n",
    "            if 'R' in roll:\n",
    "                for subdirectory in os.listdir(downloadedDir + roll):\n",
    "                    start = time.time()\n",
    "                    subdir_path_end = roll + '/' + subdirectory + '/'\n",
    "\n",
    "                    #Move to '03_processing'\n",
    "                    move_images(old_dir=downloadedDir, new_dir=processingDir, roll=roll, subdir=subdirectory)\n",
    "                    \n",
    "                    #Clear intermediate results in result_localDir\n",
    "                    for file in os.listdir(result_localDir):\n",
    "                        os.remove(result_localDir + file)\n",
    "                        '''if file == 'df_dot.csv':\n",
    "                            os.remove(resultDir + file)\n",
    "                        elif file == 'df_num.csv':\n",
    "                            os.remove(resultDir + file)\n",
    "                        elif file == 'df_loss.csv':\n",
    "                            os.remove(resultDir + file)\n",
    "                        elif file == 'df_outlier.csv':\n",
    "                            os.remove(resultDir + file)'''\n",
    "\n",
    "                    #Process\n",
    "                    print('')\n",
    "                    print('Processing ' + subdir_path_end + ' subdirectory...')\n",
    "                    !python scan2data/user_input.py $processingDir $result_localDir\n",
    "\n",
    "                    #Consolidate results\n",
    "                    if os.path.exists(result_localDir + 'df_dot.csv'):\n",
    "                        df_dot = pd.read_csv(result_localDir + 'df_dot.csv')\n",
    "                        n_dot = len(df_dot)\n",
    "                        df_dot['processed_image_class'] = 'dot'\n",
    "                        os.remove(result_localDir + 'df_dot.csv')\n",
    "                    else:\n",
    "                        df_dot = pd.DataFrame()\n",
    "                        n_dot = 0\n",
    "\n",
    "                    if os.path.exists(result_localDir + 'df_num.csv'):\n",
    "                        df_num = pd.read_csv(result_localDir + 'df_num.csv')\n",
    "                        n_num = len(df_num)\n",
    "                        df_num['processed_image_class'] = 'num'\n",
    "                        os.remove(result_localDir + 'df_num.csv')\n",
    "                    else:\n",
    "                        df_num = pd.DataFrame()\n",
    "                        n_num = 0\n",
    "\n",
    "                    if os.path.exists(resultDir + 'df_loss.csv'):\n",
    "                        df_loss = pd.read_csv(result_localDir + 'df_loss.csv')\n",
    "                        n_loss = len(df_loss)\n",
    "                        df_loss['processed_image_class'] = 'loss'\n",
    "                        os.remove(result_localDir + 'df_loss.csv')\n",
    "                    else:\n",
    "                        df_loss = pd.DataFrame()\n",
    "                        n_loss = 0\n",
    "\n",
    "                    if os.path.exists(result_localDir + 'df_outlier.csv'):\n",
    "                        df_outlier = pd.read_csv(result_localDir + 'df_outlier.csv')\n",
    "                        n_outlier = len(df_outlier)\n",
    "                        df_outlier['processed_image_class'] = 'outlier'\n",
    "                        os.remove(result_localDir + 'df_outlier.csv')\n",
    "                    else:\n",
    "                        df_outlier = pd.DataFrame()\n",
    "                        n_outlier = 0\n",
    "\n",
    "                    df_tot = pd.concat([df_dot, df_num, df_loss, df_outlier])\n",
    "                    if len(df_tot) > 0:\n",
    "                        df_tot['Roll'] = roll\n",
    "                        df_tot['Subdirectory'] = subdirectory\n",
    "                        if 'file_name' in df_tot.columns:\n",
    "                            df_tot['filename'] = df_tot['file_name'].str.replace(processingDir + roll + '/' + subdirectory, '')\n",
    "                            df_tot['filename'] = df_tot['filename'].str.replace('\\\\', '')\n",
    "                            df_tot['filename'] = df_tot['filename'].str.replace('/', '')\n",
    "                        else:\n",
    "                            df_tot['filename'] = 'unknown'\n",
    "                        df_tot = df_tot.drop(columns=['file_name', 'mapped_coord', 'subdir_name', 'raw', 'ionogram', 'raw_metadata', \n",
    "                                                      'trimmed_metadata', 'padded', 'dilated_metadata'], errors='ignore')\n",
    "                    os.makedirs(resultDir + roll + '/', exist_ok=True)\n",
    "                    df_tot.to_csv(resultDir + roll + '/' + 'result-' + roll + '_' + subdirectory + '.csv', index=False)\n",
    "                    \n",
    "                    #move mapped_coords to '05_result'\n",
    "                    mapped_coords_localDir = result_localDir + 'mapped_coords/' + subdir_path_end\n",
    "                    mapped_coordsDir = resultDir + 'mapped_coords/' + subdir_path_end\n",
    "                    move_images(old_dir=mapped_coords_localDir, new_dir=mapped_coordsDir, roll=roll, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    t = end - start\n",
    "                    print('Processing time for subdirectory: ' + str(round(t/60, 1)) + ' min')\n",
    "                    print('')\n",
    "                    \n",
    "                    #Record performance\n",
    "                    n_processed = n_dot + n_num + n_loss + n_outlier\n",
    "                    df_result_ = pd.DataFrame({\n",
    "                        'Roll': roll,\n",
    "                        'Subdirectory': subdirectory,\n",
    "                        'Images_processed': n_processed,\n",
    "                        'Images_dot': n_dot,\n",
    "                        'Images_num': n_num,\n",
    "                        'Images_loss': n_loss,\n",
    "                        'Images_outlier': n_outlier,\n",
    "                        'Process_time': t,\n",
    "                        'Process_timestamp': datetime.fromtimestamp(end),\n",
    "                        'User': user,\n",
    "                        'subdir_id': roll + '_' + subdirectory\n",
    "                    }, index=[0])\n",
    "                    if os.path.exists(logDir + 'process_log.csv'):\n",
    "                        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "                        df_update = pd.concat([df_log, df_result_], axis=0, ignore_index=True)\n",
    "                        df_update.to_csv(logDir + 'process_log.csv', index=False)\n",
    "                    else:\n",
    "                        if len(df_result_) > 0:\n",
    "                            df_result_.to_csv(logDir + 'process_log.csv', index=False)\n",
    "                    \n",
    "                    #Backup 'process_log' (10% of the time)\n",
    "                    if randrange(10) == 7:\n",
    "                        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "                        datetime_str = datetime.now().strftime(\"%Y%m%d_%Hh%M\")\n",
    "                        os.makedirs(logDir + 'backups/', exist_ok=True)\n",
    "                        df_log.to_csv(logDir + 'backups/' + 'process_log-' + datetime_str + '.csv', index=False)\n",
    "                    \n",
    "                    #Move to '04_processed' or '04a_unprocessed'\n",
    "                    if n_processed > 0:\n",
    "                        move_images(old_dir=processingDir, new_dir=processedDir, roll=roll, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "                    else:\n",
    "                        move_images(old_dir=processingDir, new_dir=unprocessedDir, roll=roll, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "                    \n",
    "                    stop_condition_counter += 1\n",
    "    \n",
    "    else:\n",
    "        #Wait\n",
    "        print('Wait ' + str(wait) + ' min')\n",
    "        time.sleep(wait*60)\n",
    "\n",
    "        \n",
    "    #Check stop conditions\n",
    "    if stop_condition_counter == stop_loop_threshold:\n",
    "        print('Stop!')\n",
    "        stop_condition = True\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d51e7e",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ce545",
   "metadata": {},
   "source": [
    "#### Re-process list of subdirectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d92172",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roll</th>\n",
       "      <th>Subdirectory</th>\n",
       "      <th>Images_processed</th>\n",
       "      <th>Images_dot</th>\n",
       "      <th>Images_num</th>\n",
       "      <th>Images_loss</th>\n",
       "      <th>Images_outlier</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Process_timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>subdir_id</th>\n",
       "      <th>Images_downloaded</th>\n",
       "      <th>Download_time</th>\n",
       "      <th>Download_timestamp</th>\n",
       "      <th>User_dl</th>\n",
       "      <th>Images_unprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R014207907F</td>\n",
       "      <td>524</td>\n",
       "      <td>712</td>\n",
       "      <td>353</td>\n",
       "      <td>306</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>671.095206</td>\n",
       "      <td>2022-12-19 20:35:24.248602</td>\n",
       "      <td>Roksana</td>\n",
       "      <td>R014207907F_524</td>\n",
       "      <td>412</td>\n",
       "      <td>79.659038</td>\n",
       "      <td>2022-12-19 20:21:24.132593</td>\n",
       "      <td>Roksana</td>\n",
       "      <td>-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R014207840</td>\n",
       "      <td>3047-53A-2-RR</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>478.103771</td>\n",
       "      <td>2022-12-20 16:31:45.168516</td>\n",
       "      <td>Rav</td>\n",
       "      <td>R014207840_3047-53A-2-RR</td>\n",
       "      <td>313</td>\n",
       "      <td>76.046123</td>\n",
       "      <td>2022-12-20 16:22:28.320731</td>\n",
       "      <td>Rav</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R014207841</td>\n",
       "      <td>3116-13B</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>230.367390</td>\n",
       "      <td>2022-12-20 18:44:10.745672</td>\n",
       "      <td>Rav</td>\n",
       "      <td>R014207841_3116-13B</td>\n",
       "      <td>302</td>\n",
       "      <td>81.163815</td>\n",
       "      <td>2022-12-20 18:35:22.252768</td>\n",
       "      <td>Rav</td>\n",
       "      <td>-61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R014207844</td>\n",
       "      <td>2945-43B</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>849.052986</td>\n",
       "      <td>2022-12-20 20:35:39.269207</td>\n",
       "      <td>Rav</td>\n",
       "      <td>R014207844_2945-43B</td>\n",
       "      <td>287</td>\n",
       "      <td>69.989887</td>\n",
       "      <td>2022-12-20 20:18:39.378767</td>\n",
       "      <td>Rav</td>\n",
       "      <td>-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R014207960</td>\n",
       "      <td>2582-18B</td>\n",
       "      <td>400</td>\n",
       "      <td>368</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>910.137281</td>\n",
       "      <td>2022-12-21 00:51:32.401796</td>\n",
       "      <td>Roksana</td>\n",
       "      <td>R014207960_2582-18B</td>\n",
       "      <td>328</td>\n",
       "      <td>86.695219</td>\n",
       "      <td>2022-12-21 00:34:34.681819</td>\n",
       "      <td>Roksana</td>\n",
       "      <td>-72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Roll   Subdirectory  Images_processed  Images_dot  Images_num  \\\n",
       "0  R014207907F            524               712         353         306   \n",
       "1   R014207840  3047-53A-2-RR               314           1         259   \n",
       "2   R014207841       3116-13B               363           0         353   \n",
       "3   R014207844       2945-43B               326           0         309   \n",
       "4   R014207960       2582-18B               400         368           5   \n",
       "\n",
       "   Images_loss  Images_outlier  Process_time           Process_timestamp  \\\n",
       "0           23              30    671.095206  2022-12-19 20:35:24.248602   \n",
       "1           43              11    478.103771  2022-12-20 16:31:45.168516   \n",
       "2            1               9    230.367390  2022-12-20 18:44:10.745672   \n",
       "3            4              13    849.052986  2022-12-20 20:35:39.269207   \n",
       "4           10              17    910.137281  2022-12-21 00:51:32.401796   \n",
       "\n",
       "      User                 subdir_id  Images_downloaded  Download_time  \\\n",
       "0  Roksana           R014207907F_524                412      79.659038   \n",
       "1      Rav  R014207840_3047-53A-2-RR                313      76.046123   \n",
       "2      Rav       R014207841_3116-13B                302      81.163815   \n",
       "3      Rav       R014207844_2945-43B                287      69.989887   \n",
       "4  Roksana       R014207960_2582-18B                328      86.695219   \n",
       "\n",
       "           Download_timestamp  User_dl  Images_unprocessed  \n",
       "0  2022-12-19 20:21:24.132593  Roksana                -300  \n",
       "1  2022-12-20 16:22:28.320731      Rav                  -1  \n",
       "2  2022-12-20 18:35:22.252768      Rav                 -61  \n",
       "3  2022-12-20 20:18:39.378767      Rav                 -39  \n",
       "4  2022-12-21 00:34:34.681819  Roksana                 -72  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reprocess = pd.read_csv(logDir + 'reprocess_list.csv')\n",
    "print(len(df_reprocess))\n",
    "df_reprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1717845",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprocess_list = df_reprocess['subdir_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing R014207907F/524/ subdirectory...\n",
      "Processing time for subdirectory: 11.7 min\n",
      "\n",
      "Cannot find subdirectory!\n",
      "\n",
      "Processing R014207841/3116-13B/ subdirectory...\n"
     ]
    }
   ],
   "source": [
    "for subdir in reprocess_list:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    subdir_id_parts = subdir.split('_')\n",
    "    roll = subdir_id_parts[0]\n",
    "    subdirectory = subdir_id_parts[1]\n",
    "    subdir_path_end = roll + '/' + subdirectory + '/'\n",
    "    \n",
    "    #Retrieve subdirectory\n",
    "    if os.path.exists(processedDir + subdir_path_end):\n",
    "        move_images(old_dir=processedDir, new_dir=processingDir, roll=roll, subdir=subdirectory, copy_to_other_drive=True)\n",
    "    elif os.path.exists(unprocessedDir + subdir_path_end):\n",
    "        move_images(old_dir=unprocessedDir, new_dir=processingDir, roll=roll, subdir=subdirectory, copy_to_other_drive=True)\n",
    "    else:\n",
    "        print('Cannot find subdirectory ' + subdir + '!')\n",
    "        continue\n",
    "    \n",
    "    #Clear intermediate results in resultDir\n",
    "    for file in os.listdir(resultDir):\n",
    "        if file == 'df_dot.csv':\n",
    "            os.remove(resultDir + file)\n",
    "        elif file == 'df_num.csv':\n",
    "            os.remove(resultDir + file)\n",
    "        elif file == 'df_loss.csv':\n",
    "            os.remove(resultDir + file)\n",
    "        elif file == 'df_outlier.csv':\n",
    "            os.remove(resultDir + file)\n",
    "    \n",
    "    #Process\n",
    "    print('')\n",
    "    print('Processing ' + subdir_path_end + ' subdirectory...')\n",
    "    !python scan2data/user_input.py $processingDir $resultDir\n",
    "\n",
    "    #Consolidate results\n",
    "    if os.path.exists(resultDir + 'df_dot.csv'):\n",
    "        df_dot = pd.read_csv(resultDir + 'df_dot.csv')\n",
    "        n_dot = len(df_dot)\n",
    "        df_dot['processed_image_class'] = 'dot'\n",
    "        os.remove(resultDir + 'df_dot.csv')\n",
    "    else:\n",
    "        df_dot = pd.DataFrame()\n",
    "        n_dot = 0\n",
    "\n",
    "    if os.path.exists(resultDir + 'df_num.csv'):\n",
    "        df_num = pd.read_csv(resultDir + 'df_num.csv')\n",
    "        n_num = len(df_num)\n",
    "        df_num['processed_image_class'] = 'num'\n",
    "        os.remove(resultDir + 'df_num.csv')\n",
    "    else:\n",
    "        df_num = pd.DataFrame()\n",
    "        n_num = 0\n",
    "\n",
    "    if os.path.exists(resultDir + 'df_loss.csv'):\n",
    "        df_loss = pd.read_csv(resultDir + 'df_loss.csv')\n",
    "        n_loss = len(df_loss)\n",
    "        df_loss['processed_image_class'] = 'loss'\n",
    "        os.remove(resultDir + 'df_loss.csv')\n",
    "    else:\n",
    "        df_loss = pd.DataFrame()\n",
    "        n_loss = 0\n",
    "\n",
    "    if os.path.exists(resultDir + 'df_outlier.csv'):\n",
    "        df_outlier = pd.read_csv(resultDir + 'df_outlier.csv')\n",
    "        n_outlier = len(df_outlier)\n",
    "        df_outlier['processed_image_class'] = 'outlier'\n",
    "        os.remove(resultDir + 'df_outlier.csv')\n",
    "    else:\n",
    "        df_outlier = pd.DataFrame()\n",
    "        n_outlier = 0\n",
    "\n",
    "    df_tot = pd.concat([df_dot, df_num, df_loss, df_outlier])\n",
    "    if len(df_tot) > 0:\n",
    "        df_tot['Roll'] = roll\n",
    "        df_tot['Subdirectory'] = subdirectory\n",
    "        if 'file_name' in df_tot.columns:\n",
    "            df_tot['filename'] = df_tot['file_name'].str.replace(processingDir + roll + '/' + subdirectory, '')\n",
    "            df_tot['filename'] = df_tot['filename'].str.replace('\\\\', '')\n",
    "            df_tot['filename'] = df_tot['filename'].str.replace('/', '')\n",
    "        else:\n",
    "            df_tot['filename'] = 'unknown'\n",
    "        df_tot = df_tot.drop(columns=['file_name', 'mapped_coord', 'subdir_name', 'raw', 'ionogram', 'raw_metadata', \n",
    "                                      'trimmed_metadata', 'padded', 'dilated_metadata'], errors='ignore')\n",
    "    os.makedirs(resultDir + roll + '/', exist_ok=True)\n",
    "    df_tot.to_csv(resultDir + roll + '/' + 'result-' + roll + '_' + subdirectory + '.csv', index=False)\n",
    "\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print('Processing time for subdirectory: ' + str(round(t/60, 1)) + ' min')\n",
    "    print('')\n",
    "\n",
    "    #Record performance\n",
    "    n_processed = n_dot + n_num + n_loss + n_outlier\n",
    "    df_result_ = pd.DataFrame({\n",
    "        'Roll': roll,\n",
    "        'Subdirectory': subdirectory,\n",
    "        'Images_processed': n_processed,\n",
    "        'Images_dot': n_dot,\n",
    "        'Images_num': n_num,\n",
    "        'Images_loss': n_loss,\n",
    "        'Images_outlier': n_outlier,\n",
    "        'Process_time': t,\n",
    "        'Process_timestamp': datetime.fromtimestamp(end),\n",
    "        'User': user,\n",
    "        'subdir_id': roll + '_' + subdirectory\n",
    "    }, index=[0])\n",
    "    if os.path.exists(logDir + 'process_log.csv'):\n",
    "        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "        df_update = pd.concat([df_log, df_result_], axis=0, ignore_index=True)\n",
    "        df_update.to_csv(logDir + 'process_log.csv', index=False)\n",
    "    else:\n",
    "        if len(df_result_) > 0:\n",
    "            df_result_.to_csv(logDir + 'process_log.csv', index=False)\n",
    "\n",
    "    #Backup 'process_log' (10% of the time)\n",
    "    if randrange(10) == 7:\n",
    "        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "        datetime_str = datetime.now().strftime(\"%Y%m%d_%Hh%M\")\n",
    "        os.makedirs(logDir + 'backups/', exist_ok=True)\n",
    "        df_log.to_csv(logDir + 'backups/' + 'process_log-' + datetime_str + '.csv', index=False)\n",
    "\n",
    "    #Move to '04_processed' or '04a_unprocessed'\n",
    "    if n_processed > 0:\n",
    "        move_images(old_dir=processingDir, new_dir=processedDir, roll=roll, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "    else:\n",
    "        move_images(old_dir=processingDir, new_dir=unprocessedDir, roll=roll, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6ba39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
