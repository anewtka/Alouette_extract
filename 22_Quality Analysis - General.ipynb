{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa42cc82",
   "metadata": {},
   "source": [
    "# Quality Analysis - General\n",
    "\n",
    "#### Updated: May 17, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba88fc",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247d7b9",
   "metadata": {},
   "source": [
    "Quality analysis pipeline after phase 2 of Alouette processing (OCR processing phase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5ed871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e42a259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir = 'L:/DATA/Alouette_I/BATCH_II_Run2/'\n",
    "resultDir = rootDir + '05_result/'\n",
    "logDir = rootDir + '06_log/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f85e5",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23d356",
   "metadata": {},
   "source": [
    "#### Combine BATCH I and II:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a628c",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e76aa",
   "metadata": {},
   "source": [
    "#### Stage 1 - Overall Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3115f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventory = pd.read_csv(logDir + 'image_inventory.csv')\n",
    "n_images = df_inventory['images'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8da00a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s1 = pd.read_csv(resultDir + 'result_stage1_raw.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8f81c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc = len(df_s1.loc[df_s1['processed_image_class'] == 'num']) + len(df_s1.loc[df_s1['processed_image_class'] == 'dot'])\n",
    "n_loss = len(df_s1.loc[df_s1['processed_image_class'] == 'loss'])\n",
    "n_outlier = len(df_s1.loc[df_s1['processed_image_class'] == 'outlier'])\n",
    "n_unproc = n_images - n_proc - n_outlier - n_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c20872f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images: 726577\n",
      "# of images processed after stage 1 processing: 449732\n",
      "% of images processed after stage 1 processing: 61.9 %\n",
      "\n",
      "% total loss after stage 1 processing: 38.1 %\n",
      "% of images unprocessed after stage 1 processing: 17.34 %\n",
      "% of images classified as 'loss' after stage 1 processing: 13.07 %\n",
      "% of images classified as 'outlier' after stage 1 processing: 7.7 %\n"
     ]
    }
   ],
   "source": [
    "print('# of images: ' + str(n_images))\n",
    "print('# of images processed after stage 1 processing: ' + str(n_proc))\n",
    "print('% of images processed after stage 1 processing: ' + str(round(((n_proc/n_images)*100), 2)) + ' %')\n",
    "print('')\n",
    "print(\"% total loss after stage 1 processing: \" + str(round((((n_unproc + n_loss + n_outlier)/n_images)*100), 2)) + ' %')\n",
    "print('% of images unprocessed after stage 1 processing: ' + str(round(((n_unproc/n_images)*100), 2)) + ' %')\n",
    "print(\"% of images classified as 'loss' after stage 1 processing: \" + str(round(((n_loss/n_images)*100), 2)) + ' %')\n",
    "print(\"% of images classified as 'outlier' after stage 1 processing: \" + str(round(((n_outlier/n_images)*100), 2)) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2237ef",
   "metadata": {},
   "source": [
    "Breakdown 'loss' type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "67f7f41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metadata_translation.determine_leftside_metadata_grid_mapping.extract_centroids_and_determine_type</th>\n",
       "      <td>37872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionogram_content_extraction.extract_select_parameters.extract_fmin_and_max_depth</th>\n",
       "      <td>9521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_segmentation.trim_raw_metadata.trimming_metadata</th>\n",
       "      <td>3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_segmentation.extract_ionogram_from_scan.extract_ionogram</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    filename\n",
       "func_name                                                   \n",
       "metadata_translation.determine_leftside_metadat...     37872\n",
       "ionogram_content_extraction.extract_select_para...      9521\n",
       "image_segmentation.trim_raw_metadata.trimming_m...      3968\n",
       "image_segmentation.extract_ionogram_from_scan.e...         1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss_bd = df_s1.loc[df_s1['processed_image_class'] == 'loss'].groupby(['func_name']).count()[['filename']]\n",
    "df_loss_bd.sort_values('filename', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21c1bd",
   "metadata": {},
   "source": [
    "Breakdown 'outlier' type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d4755c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_segmentation.segment_images_in_subdir.segment_images: iono size outlier</th>\n",
       "      <td>54428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_segmentation.segment_images_in_subdir.segment_images: metadata size outlier</th>\n",
       "      <td>1511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    filename\n",
       "func_name                                                   \n",
       "image_segmentation.segment_images_in_subdir.seg...     54428\n",
       "image_segmentation.segment_images_in_subdir.seg...      1511"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_bd = df_s1.loc[df_s1['processed_image_class'] == 'outlier'].groupby(['func_name']).count()[['filename']]\n",
    "df_outlier_bd.sort_values('filename', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b5059",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878409b",
   "metadata": {},
   "source": [
    "#### Stage 2 - Overall Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ff1b58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s2 = pd.read_csv(resultDir + 'result_stage2_raw.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1453d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_num2 = len(df_s2.loc[df_s2['processed_image_class'] == 'num2'])\n",
    "n_num = len(df_s2.loc[df_s2['processed_image_class'] == 'num'])\n",
    "n_dot = len(df_s2.loc[df_s2['processed_image_class'] == 'dot'])\n",
    "n_proc2 = n_num2 + n_num + n_dot\n",
    "n_loss = len(df_s2.loc[df_s2['processed_image_class'] == 'loss'])\n",
    "n_outlier = len(df_s2.loc[df_s2['processed_image_class'] == 'outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8ac57beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images processed after stage 2 processing: 18120\n",
      "% of images processed after stage 2 processing: 2.49 %\n",
      "\n",
      "% of images classified as 'num2' after stage 2 processing: 0.87 %\n",
      "% of images classified as 'num' after stage 2 processing: 1.49 %\n",
      "% of images classified as 'dot' after stage 2 processing: 0.14 %\n",
      "\n",
      "% total loss after stage 2 processing: 20.94 %\n",
      "% of images classified as 'loss' after stage 2 processing: 2.92 %\n",
      "% of images classified as 'outlier' after stage 2 processing: 0.68 %\n"
     ]
    }
   ],
   "source": [
    "print('# of images processed after stage 2 processing: ' + str(n_proc2))\n",
    "print('% of images processed after stage 2 processing: ' + str(round(((n_proc2/n_images)*100), 2)) + ' %')\n",
    "print('')\n",
    "print(\"% of images classified as 'num2' after stage 2 processing: \" + str(round(((n_num2/n_images)*100), 2)) + ' %')\n",
    "print(\"% of images classified as 'num' after stage 2 processing: \" + str(round(((n_num/n_images)*100), 2)) + ' %')\n",
    "print(\"% of images classified as 'dot' after stage 2 processing: \" + str(round(((n_dot/n_images)*100), 2)) + ' %')\n",
    "print('')\n",
    "print(\"% total loss after stage 2 processing: \" + str(round((((n_unproc + n_loss + n_outlier)/n_images)*100), 2)) + ' %')\n",
    "print(\"% of images classified as 'loss' after stage 2 processing: \" + str(round(((n_loss/n_images)*100), 2)) + ' %')\n",
    "print(\"% of images classified as 'outlier' after stage 2 processing: \" + str(round(((n_outlier/n_images)*100), 2)) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d74081",
   "metadata": {},
   "source": [
    "Breakdown 'loss' type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "711384ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_summary</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_segmentation.segment_images_in_subdir.segment_images: iono size outlier, OCR read metadata contains letters</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionogram_content_extraction.extract_select_parameters.extract_fmin_and_max_depth, OCR read metadata contains letters</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_segmentation.trim_raw_metadata.trimming_metadata, OCR read metadata contains letters</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata_translation.determine_leftside_metadata_grid_mapping.extract_centroids_and_determine_type, OCR read metadata contains letters</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_segmentation.segment_images_in_subdir.segment_images: metadata size outlier, OCR read metadata contains letters</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    filename\n",
       "loss_summary                                                \n",
       "image_segmentation.segment_images_in_subdir.seg...       129\n",
       "ionogram_content_extraction.extract_select_para...        25\n",
       "image_segmentation.trim_raw_metadata.trimming_m...         6\n",
       "metadata_translation.determine_leftside_metadat...         3\n",
       "image_segmentation.segment_images_in_subdir.seg...         1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s2_loss = df_s2.copy(deep=True).loc[df_s2['processed_image_class'] == 'loss']\n",
    "df_s2_loss['loss_summary'] = df_s2_loss['func_name'] + ', ' + df_s2_loss['details'] \n",
    "df_loss_bd = df_s2_loss.groupby(['loss_summary']).count()[['filename']]\n",
    "df_loss_bd.sort_values('filename', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1247dab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metadata could not be read by OCR</th>\n",
       "      <td>10102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCR read metadata contains letters</th>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata was interpreted to be num type</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata was interpreted to be dot type</th>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename\n",
       "details                                          \n",
       "metadata could not be read by OCR           10102\n",
       "OCR read metadata contains letters           1282\n",
       "metadata was interpreted to be num type       294\n",
       "metadata was interpreted to be dot type       242"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s2_loss = df_s2.loc[df_s2['processed_image_class'] == 'loss']\n",
    "df_loss_bd = df_s2_loss.groupby(['details']).count()[['filename']]\n",
    "df_loss_bd.sort_values('filename', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474347e0",
   "metadata": {},
   "source": [
    "Breakdown 'outlier' type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "56c6fa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_segmentation.segment_images_in_subdir.segment_images: iono size outlier</th>\n",
       "      <td>4656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_segmentation.segment_images_in_subdir.segment_images: metadata size outlier</th>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    filename\n",
       "func_name                                                   \n",
       "image_segmentation.segment_images_in_subdir.seg...      4656\n",
       "image_segmentation.segment_images_in_subdir.seg...       314"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s2_outlier = df_s2.loc[df_s2['processed_image_class'] == 'outlier']\n",
    "df_outlier_bd = df_s2_outlier.groupby(['func_name']).count()[['filename']]\n",
    "df_outlier_bd.sort_values('filename', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20289cfc",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e161c",
   "metadata": {},
   "source": [
    "#### Master - Overall Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1624123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv(resultDir + 'result_master.csv', low_memory=False)\n",
    "n_master = len(df_master.loc[(~pd.isna(df_master['Station_Code'])) & (df_master['time_quality'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5e3574f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tq1 = len(df_master.loc[df_master['time_quality'] == 1])\n",
    "n_tq2 = len(df_master.loc[df_master['time_quality'] == 2])\n",
    "n_tq3 = len(df_master.loc[df_master['time_quality'] == 3])\n",
    "n_tq4 = len(df_master.loc[df_master['time_quality'] == 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7eb7af18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images fully read after stage 2 processing: 12970\n",
      "% of images fully read after stage 2 processing (yield): 1.79 %\n",
      "\n",
      "% time quality level 1 yield: 1.79 %\n",
      "% at least time quality level 2: 1.79 %\n",
      "% at least time quality level 3: 1.81 %\n",
      "% at least time quality level 4: 1.9 %\n"
     ]
    }
   ],
   "source": [
    "print('# of images fully read after stage 2 processing: ' + str(n_master))\n",
    "print('% of images fully read after stage 2 processing (yield): ' + str(round(((n_master/n_images)*100), 2)) + ' %')\n",
    "print('')\n",
    "print('% time quality level 1 yield: ' + str(round(((n_tq1/n_images)*100), 2)) + ' %')\n",
    "print('% at least time quality level 2: ' + str(round((((n_tq1+n_tq2)/n_images)*100), 2)) + ' %')\n",
    "print('% at least time quality level 3: ' + str(round((((n_tq1+n_tq2+n_tq3)/n_images)*100), 2)) + ' %')\n",
    "print('% at least time quality level 4: ' + str(round((((n_tq1+n_tq2+n_tq3+n_tq4)/n_images)*100), 2)) + ' %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
