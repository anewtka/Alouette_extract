{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2233f4a8",
   "metadata": {},
   "source": [
    "# How to train keras_OCR with ISIS ionograms\n",
    "\n",
    "## 1. Prepare dataset\n",
    "I selected randomly 60 ionograms of ISIS. I than created a csv file with annotations. Here's how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ab65d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "      <td>316</td>\n",
       "      <td>361</td>\n",
       "      <td>601</td>\n",
       "      <td>402</td>\n",
       "      <td>36 00 69 111 0354 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.png</td>\n",
       "      <td>457</td>\n",
       "      <td>363</td>\n",
       "      <td>746</td>\n",
       "      <td>405</td>\n",
       "      <td>36 00 69 111 0245 04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.png</td>\n",
       "      <td>481</td>\n",
       "      <td>369</td>\n",
       "      <td>767</td>\n",
       "      <td>403</td>\n",
       "      <td>36 00 69 101 0245 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.png</td>\n",
       "      <td>510</td>\n",
       "      <td>366</td>\n",
       "      <td>793</td>\n",
       "      <td>402</td>\n",
       "      <td>36 00 69 111 0245 58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.png</td>\n",
       "      <td>492</td>\n",
       "      <td>368</td>\n",
       "      <td>774</td>\n",
       "      <td>402</td>\n",
       "      <td>36 00 69 111 0246 25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_path  x_min  y_min  x_max  y_max          text_content\n",
       "0      1.png    316    361    601    402  36 00 69 111 0354 35\n",
       "1      2.png    457    363    746    405  36 00 69 111 0245 04\n",
       "2      3.png    481    369    767    403  36 00 69 101 0245 31\n",
       "3      4.png    510    366    793    402  36 00 69 111 0245 58\n",
       "4      5.png    492    368    774    402  36 00 69 111 0246 25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ann = pd.read_csv('L:/DATA/ISIS/keras_ocr/annotations/global_annotations.csv')\n",
    "ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54822009",
   "metadata": {},
   "source": [
    "The columns (x_min, y_min) and (x_max, y_max) define the top left corner and the bottom right corner of a box around the metadata. I found those values manually in paint. It took me around 1h30 to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa93296",
   "metadata": {},
   "source": [
    "## 2. Split the dataset\n",
    "I need to create three subsets : training, validation and test sets. Since I only have 60 images, I'll use the 70-15-15 ratio to create the subsets. The first step is to shuffle the dataset randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1abc1b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.png</td>\n",
       "      <td>160</td>\n",
       "      <td>374</td>\n",
       "      <td>561</td>\n",
       "      <td>404</td>\n",
       "      <td>41 16 71 364 1949 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.png</td>\n",
       "      <td>421</td>\n",
       "      <td>367</td>\n",
       "      <td>709</td>\n",
       "      <td>400</td>\n",
       "      <td>36 00 69 111 0248 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.png</td>\n",
       "      <td>232</td>\n",
       "      <td>465</td>\n",
       "      <td>727</td>\n",
       "      <td>502</td>\n",
       "      <td>45 19 72 065 0205 01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.png</td>\n",
       "      <td>510</td>\n",
       "      <td>366</td>\n",
       "      <td>793</td>\n",
       "      <td>402</td>\n",
       "      <td>36 00 69 111 0245 58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.png</td>\n",
       "      <td>241</td>\n",
       "      <td>374</td>\n",
       "      <td>642</td>\n",
       "      <td>404</td>\n",
       "      <td>41 16 71 364 1950 18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_path  x_min  y_min  x_max  y_max          text_content\n",
       "0     26.png    160    374    561    404  41 16 71 364 1949 34\n",
       "1      9.png    421    367    709    400  36 00 69 111 0248 13\n",
       "2     18.png    232    465    727    502  45 19 72 065 0205 01\n",
       "3      4.png    510    366    793    402  36 00 69 111 0245 58\n",
       "4     29.png    241    374    642    404  41 16 71 364 1950 18"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = ann.sample(frac = 1)\n",
    "ann.reset_index(drop=True, inplace=True)\n",
    "ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86b3154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subsets and save them\n",
    "train = ann[0:42]\n",
    "train.to_csv('L:/DATA/ISIS/keras_ocr/train/annotations/train_annotations.csv',index=False)\n",
    "\n",
    "val = ann[42:51]\n",
    "val.to_csv('L:/DATA/ISIS/keras_ocr/val/annotations/val_annotations.csv',index=False)\n",
    "\n",
    "test = ann[51:60]\n",
    "test.to_csv('L:/DATA/ISIS/keras_ocr/test/annotations/test_annotations.csv',index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01b1b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Initialise the directories for training, validation and testing (remove current images)\n",
    "train_dir = 'L:/DATA/ISIS/keras_ocr/train/'\n",
    "val_dir = 'L:/DATA/ISIS/keras_ocr/val/'\n",
    "test_dir = 'L:/DATA/ISIS/keras_ocr/test/'\n",
    "\n",
    "for path in [train_dir, val_dir, test_dir]:\n",
    "    for f in os.listdir(path+'images/'):\n",
    "        os.remove(os.path.join(path+'images/', f))\n",
    "\n",
    "all_images = os.listdir('L:/DATA/ISIS/keras_ocr/all images')\n",
    "\n",
    "# copy images for all subsets\n",
    "for image in all_images :\n",
    "    full_name = os.path.join('L:/DATA/ISIS/keras_ocr/all images/', image)\n",
    "    if image in train['image_path'].to_list():\n",
    "        shutil.copy(full_name, train_dir+'images/'+image)\n",
    "    elif image in val['image_path'].to_list():\n",
    "        shutil.copy(full_name, val_dir+'images/'+image)\n",
    "    elif image in test['image_path'].to_list():\n",
    "        shutil.copy(full_name, test_dir+'images/'+image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3935b7c",
   "metadata": {},
   "source": [
    "## 3. Create data generators\n",
    "\n",
    "To create our data generators, we'll code our own class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47cb47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28559874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRDataGenerator(Sequence):\n",
    "    def __init__(self, annotations_file, image_dir, batch_size):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.annotations) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        batch_annotations = self.annotations.iloc[batch_indices]\n",
    "        images, targets = self._load_batch(batch_annotations)\n",
    "        return images, targets\n",
    "\n",
    "    def _load_batch(self, batch_annotations):\n",
    "        images = []\n",
    "        targets = []\n",
    "\n",
    "        for _, row in batch_annotations.iterrows():\n",
    "            image_path = os.path.join(self.image_dir, row['image_path'])\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image not found or cannot be loaded - {image_path}\")\n",
    "                continue\n",
    "                \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            images.append(image)\n",
    "\n",
    "            # Process the annotations to create the targets for the detection model\n",
    "            # The format for the detection target should be a list of dictionaries,\n",
    "            # each containing the bounding box coordinates and text content.\n",
    "            target = {\n",
    "                'boxes': np.array([[row['x_min'], row['y_min'], row['x_max'], row['y_max']]]),\n",
    "                'text': [row['text_content']]\n",
    "            }\n",
    "            targets.append(target)\n",
    "\n",
    "        images = np.array(images,dtype='object')\n",
    "        targets = np.array(targets,dtype='object')\n",
    "        return images, targets\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.annotations))\n",
    "        np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406b33b",
   "metadata": {},
   "source": [
    "We then create a generator for training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e13ebb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = OCRDataGenerator(annotations_file=train_dir+'annotations/train_annotations.csv',\n",
    "                                   image_dir=train_dir+'images/',\n",
    "                                   batch_size=7)\n",
    "\n",
    "val_generator = OCRDataGenerator(annotations_file=val_dir+'annotations/val_annotations.csv',\n",
    "                                 image_dir=val_dir+'images/',\n",
    "                                 batch_size=7)\n",
    "\n",
    "test_generator = OCRDataGenerator(annotations_file=test_dir+'annotations/test_annotations.csv',\n",
    "                                  image_dir=test_dir+'images/',\n",
    "                                  batch_size=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e68b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_ocr.detection import Detector\n",
    "from keras_ocr.recognition import Recognizer\n",
    "from keras_ocr.pipeline import Pipeline\n",
    "from keras_ocr.datasets import get_detector_image_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dcf2ff16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_detector_image_generator at 0x00000268028B43C0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_generator = get_detector_image_generator(train_dir+'images/'+train['image_path'],width=400,height=1100)\n",
    "detector_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "880ec6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\mfortier\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\mfortier\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "detector = Detector()\n",
    "recognizer = Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3712d6f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-19a8a5f30532>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetector_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras_ocr\\datasets.py\u001b[0m in \u001b[0;36mget_detector_image_generator\u001b[1;34m(labels, width, height, augmenter, area_threshold, focused, min_area, shuffle)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mimage_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maugmenter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "detector.model.fit(detector_generator, batch_size=7, epochs=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4b361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
