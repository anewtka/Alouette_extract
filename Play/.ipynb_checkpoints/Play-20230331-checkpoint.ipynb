{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import keras_ocr\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c59493",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir_path = 'L:/DATA/Alouette_I/BATCH_II_Run1/04_processed/R014207817/4163-03A/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fns = []\n",
    "for file in os.listdir(subdir_path):\n",
    "    img_fns.append(subdir_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 4\n",
    "batch_f = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be130e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "imgs_ocr = [\n",
    "    keras_ocr.tools.read(img) for img in img_fns[batch_i:batch_f]\n",
    "]\n",
    "\n",
    "end = time.time()\n",
    "t = end - start\n",
    "print('Time to read all images in subdirectory: ' + str(round(t/60, 1)) + ' min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa26de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "prediction_groups = pipeline.recognize(img_fns[batch_i:batch_f])\n",
    "end = time.time()\n",
    "t = end - start\n",
    "print('Time to ocr process all images in subdirectory: ' + str(round(t/60, 1)) + ' min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ef82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "for i in range(0, len(prediction_groups)):\n",
    "    df_ocr = pd.DataFrame()\n",
    "    predicted_image = prediction_groups[i]\n",
    "    if len(predicted_image) > 0:\n",
    "        for text, box in predicted_image:\n",
    "            row = pd.DataFrame({\n",
    "                'number': text,\n",
    "                'x': box[1][0],\n",
    "                'y': box[1][1]\n",
    "            }, index=[0])\n",
    "            df_ocr = pd.concat([df_ocr, row])\n",
    "        df_ocr = df_ocr.sort_values('x').reset_index(drop=True)\n",
    "    if len(df_ocr) == 6:\n",
    "        if df_ocr['number'].iloc[0] == '10':\n",
    "            row2 = pd.DataFrame({\n",
    "                'station_number': df_ocr['number'].iloc[1],\n",
    "                'year': df_ocr['number'].iloc[2],\n",
    "                'day_of_year': df_ocr['number'].iloc[3],\n",
    "                'hour': df_ocr['number'].iloc[4][0:2],\n",
    "                'minute': df_ocr['number'].iloc[4][2:],\n",
    "                'second': df_ocr['number'].iloc[5],\n",
    "                'filename': img_fns[batch_i + i].replace(subdir_path, '')\n",
    "            }, index=[0])\n",
    "            df_results = pd.concat([df_results, row2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ead90",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fn = subdir_path + '102.png'\n",
    "img = mpimg.imread(img_fn)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a886a32",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea25fb",
   "metadata": {},
   "source": [
    "Clearly the default recognizer is not adequate, as it can sometimes classify fuzzy numbers as letters.\n",
    "\n",
    "We will need to 'fine-tune' the recognizer to only recognize numbers:\n",
    "\n",
    "Ref: https://keras-ocr.readthedocs.io/en/latest/examples/fine_tuning_recognizer.html <br>\n",
    "Ref (better): https://keras-ocr.readthedocs.io/en/stable/examples/end_to_end_training.html <br>\n",
    "Ref: https://github.com/faustomorales/keras-ocr/issues/54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e059b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import datetime\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.model_selection\n",
    "\n",
    "import keras_ocr\n",
    "\n",
    "#assert tf.test.is_gpu_available(), 'No GPU is available.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49f4d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/fonts.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering fonts.:  37%|███▋      | 1012/2746 [00:03<00:10, 169.72it/s]58295 extra bytes in post.stringData array\n",
      "Filtering fonts.: 100%|██████████| 2746/2746 [00:12<00:00, 212.95it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/'\n",
    "alphabet = string.digits + ''  #+ string.ascii_letters + '!?. '\n",
    "recognizer_alphabet = ''.join(sorted(set(alphabet.lower())))\n",
    "fonts = keras_ocr.data_generation.get_fonts(\n",
    "    alphabet=alphabet,\n",
    "    cache_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef28025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds.zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\users\\\\rnaidoo\\\\Documents\\\\Projects_data\\\\Alouette_I\\\\keras_ocr\\\\backgrounds\\\\1024px-%d0%9a%d1%80%d0%b8%d1%81%d1%82%d0%b0%d0%bb%d0%bb%d1%8b_%d0%b2_%d0%b2%d1%8b%d1%81%d0%be%d1%85%d1%88%d0%b5%d0%b9_%d0%ba%d0%b0%d0%bf%d0%bb%d0%b5_%d0%9a%d0%be%d0%ba%d0%b0_%d0%9a%d0%be%d0%bb%d1%8b.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-6c47eceab677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     backgrounds.append(data_dir+'backgrounds_Alouette_I/65.jpg')'''\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbackgrounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_generation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_backgrounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras_ocr\\data_generation.py\u001b[0m in \u001b[0;36mget_backgrounds\u001b[1;34m(cache_dir)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackgrounds_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1035\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackgrounds_zip_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mzfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackgrounds_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackgrounds_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"*.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1646\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1700\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1701\u001b[1;33m              \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1702\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\users\\\\rnaidoo\\\\Documents\\\\Projects_data\\\\Alouette_I\\\\keras_ocr\\\\backgrounds\\\\1024px-%d0%9a%d1%80%d0%b8%d1%81%d1%82%d0%b0%d0%bb%d0%bb%d1%8b_%d0%b2_%d0%b2%d1%8b%d1%81%d0%be%d1%85%d1%88%d0%b5%d0%b9_%d0%ba%d0%b0%d0%bf%d0%bb%d0%b5_%d0%9a%d0%be%d0%ba%d0%b0_%d0%9a%d0%be%d0%bb%d1%8b.jpg'"
     ]
    }
   ],
   "source": [
    "'''backgrounds = []\n",
    "for i in range(0, 100):\n",
    "    backgrounds.append(data_dir+'backgrounds_Alouette_I/18.jpg')\n",
    "    backgrounds.append(data_dir+'backgrounds_Alouette_I/47.jpg')\n",
    "    backgrounds.append(data_dir+'backgrounds_Alouette_I/65.jpg')'''\n",
    "\n",
    "#backgrounds = keras_ocr.data_generation.get_backgrounds(cache_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87fbcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgrounds = os.listdir(data_dir + 'backgrounds_KerasOCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad72b7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first generated text is: \n"
     ]
    }
   ],
   "source": [
    "text_generator = keras_ocr.data_generation.get_text_generator(alphabet=alphabet)\n",
    "print('The first generated text is:', next(text_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ca28819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_split(arr):\n",
    "    train, valtest = sklearn.model_selection.train_test_split(arr, train_size=0.8, random_state=42)\n",
    "    val, test = sklearn.model_selection.train_test_split(valtest, train_size=0.5, random_state=42)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5938092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backgrounds = np.argmax(backgrounds, axis=0)\n",
    "background_splits = get_train_val_test_split(backgrounds)\n",
    "font_splits = get_train_val_test_split(fonts)\n",
    "\n",
    "image_generators = [\n",
    "    keras_ocr.data_generation.get_image_generator(\n",
    "        height=640,\n",
    "        width=640,\n",
    "        text_generator=text_generator,\n",
    "        font_groups={\n",
    "            alphabet: current_fonts\n",
    "        },\n",
    "        backgrounds=current_backgrounds,\n",
    "        font_size=(60, 120),\n",
    "        margin=50,\n",
    "        rotationX=(-0.05, 0.05),\n",
    "        rotationY=(-0.05, 0.05),\n",
    "        rotationZ=(-15, 15)\n",
    "    )  for current_fonts, current_backgrounds in zip(\n",
    "        font_splits,\n",
    "        background_splits\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45520997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/65.jpg',\n",
       "  'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/18.jpg',\n",
       "  'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/65.jpg',\n",
       "  'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/65.jpg',\n",
       "  'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/47.jpg',\n",
       "  'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/18.jpg',\n",
       "  'C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/18.jpg'],\n",
       " ['C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/47.jpg'],\n",
       " ['C:/users/rnaidoo/Documents/Projects_data/Alouette_I/keras_ocr/backgrounds_Alouette_I/47.jpg'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e89421c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<generator object get_image_generator at 0x0000021AFFBA7270>,\n",
       " <generator object get_image_generator at 0x0000021AFFBA7190>,\n",
       " <generator object get_image_generator at 0x0000021AFFBA70B0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd24823f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_image_generator at 0x0000021AFFBA7190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_generators[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfe91773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_image_generator at 0x0000021AFFBA7190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(image_generators[1], image_generators[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "011ba91b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-fa9dcc5ec502>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# See what the first validation image looks like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_generators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_generation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_lines_to_paragraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The first generated validation image (below) contains:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# See what the first validation image looks like.\n",
    "image, lines = next(image_generators[1])\n",
    "text = keras_ocr.data_generation.convert_lines_to_paragraph(lines)\n",
    "print('The first generated validation image (below) contains:', text)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b97fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\rnaidoo\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Provided alphabet does not match pretrained alphabet. Using backbone weights only.\n",
      "Looking for C:\\Users\\rnaidoo\\.keras-ocr\\crnn_kurapan_notop.h5\n"
     ]
    }
   ],
   "source": [
    "detector = keras_ocr.detection.Detector(weights='clovaai_general')\n",
    "recognizer = keras_ocr.recognition.Recognizer(\n",
    "    alphabet=recognizer_alphabet,\n",
    "    weights='kurapan'\n",
    ")\n",
    "recognizer.compile()\n",
    "for layer in recognizer.backbone.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64dffc36",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-0eacf1bfbed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     ) for image_generator in image_generators\n\u001b[0;32m      8\u001b[0m ]\n\u001b[1;32m----> 9\u001b[1;33m detector.model.fit(\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdetection_train_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdetector_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "detector_batch_size = 1\n",
    "detector_basepath = os.path.join(data_dir, f'detector_{datetime.datetime.now().isoformat()}')\n",
    "detection_train_generator, detection_val_generator, detection_test_generator = [\n",
    "    detector.get_batch_generator(\n",
    "        image_generator=image_generator,\n",
    "        batch_size=detector_batch_size\n",
    "    ) for image_generator in image_generators\n",
    "]\n",
    "detector.model.fit(\n",
    "    detection_train_generator,\n",
    "    steps_per_epoch=math.ceil(3/detector_batch_size),\n",
    "    epochs=1000,\n",
    "    workers=0,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),\n",
    "        tf.keras.callbacks.CSVLogger(f'{detector_basepath}.csv'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'{detector_basepath}.h5')\n",
    "    ],\n",
    "    validation_data=detection_val_generator,\n",
    "    validation_steps=math.ceil(3/detector_batch_size),\n",
    "    batch_size=detector_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80c137",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = keras_ocr.recognition.Recognizer(alphabet=alphabet, weights=None)#'kurapan')\n",
    "recognizer.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69eb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = recognizer.recognize(subdir_path + '102.png')\n",
    "#predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470399bc",
   "metadata": {},
   "source": [
    "Use 'Born Digital' training set to re-train model with new alphabet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ea3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = keras_ocr.datasets.get_born_digital_recognizer_dataset(\n",
    "    split='train',\n",
    "    cache_dir='.'\n",
    ")\n",
    "test_labels = keras_ocr.datasets.get_born_digital_recognizer_dataset(\n",
    "    split='test',\n",
    "    cache_dir='.'\n",
    ")\n",
    "train_labels = [(filepath, box, word.lower()) for filepath, box, word in train_labels]\n",
    "test_labels = [(filepath, box, word.lower()) for filepath, box, word in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "augmenter = imgaug.augmenters.Sequential([\n",
    "    imgaug.augmenters.GammaContrast(gamma=(0.25, 3.0)),\n",
    "])\n",
    "\n",
    "train_labels, validation_labels = sklearn.model_selection.train_test_split(train_labels, test_size=0.2, random_state=42)\n",
    "(training_image_gen, training_steps), (validation_image_gen, validation_steps) = [\n",
    "    (\n",
    "        keras_ocr.datasets.get_recognizer_image_generator(\n",
    "            labels=labels,\n",
    "            height=recognizer.model.input_shape[1],\n",
    "            width=recognizer.model.input_shape[2],\n",
    "            alphabet=alphabet,\n",
    "            augmenter=augmenter\n",
    "        ),\n",
    "        len(labels) // batch_size\n",
    "    ) for labels, augmenter in [(train_labels, augmenter), (validation_labels, None)]\n",
    "]\n",
    "training_gen, validation_gen = [\n",
    "    recognizer.get_batch_generator(\n",
    "        image_generator=image_generator,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    for image_generator in [training_image_gen, validation_image_gen]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, text = next(training_image_gen)\n",
    "print('text:', text)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, restore_best_weights=False),\n",
    "    tf.keras.callbacks.ModelCheckpoint('recognizer_borndigital.h5', monitor='val_loss', save_best_only=True),\n",
    "    tf.keras.callbacks.CSVLogger('recognizer_borndigital.csv')\n",
    "]\n",
    "recognizer.model.fit(\n",
    "    training_gen,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    validation_data=validation_gen,\n",
    "    callbacks=callbacks,\n",
    "    epochs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaec6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
