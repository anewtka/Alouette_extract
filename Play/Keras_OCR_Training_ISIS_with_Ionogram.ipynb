{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2033bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'L:/DATA/ISIS/keras_ocr/'\n",
    "\n",
    "import os\n",
    "import math\n",
    "import imgaug\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e56eca",
   "metadata": {},
   "source": [
    "## Train the recognizer\n",
    "After some research, training the detector seems hard and time consuming, so we'll start by training the recognizer with our own pictures. To train the recognizer, we need small images of digits from ionograms. I cropped 60 ionograms and their metadata. After doing some tests, I came to realize that the detector was working better when the images are only black and white, so I did a little bit of pre-processing (see the Notebook *Pre-process training images*). Here how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2471c75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181ee034100>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADYCAYAAADyIbgIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbc0lEQVR4nO3dbYyeVZkH8P+ftkihYF+mb0KhrprdNQSLTlgMmw2CGpZsFt3ERDZruolJ/aAJJiZrdZNV9xMffNlN3JjUhRWzrob4BjGu2rAaY7JBp1ixtSCuVFo7zLRAX0AsTHvth7mJw9z/i7nP8zY9w/+XNNM53M9zn3M/93N4+lzXdQ4jAmZmVp/zFrsDZmbWG0/gZmaV8gRuZlYpT+BmZpXyBG5mVilP4GZmleprAid5E8mHSf6K5M5BdcrMzBbGXvPASS4D8EsAbwNwGMBPANwaEb/IHjM2NhZbt27t6Xzniq7Xi2Tnx2fHnj17ttV23nn+R1PJdel6bPa6Zq/NUrRnzx7Z/qY3vanzc5w5c6bVtmzZsp77ZLP27NlzLCLWz29f3sdzXgPgVxHxawAg+RUAtwBIJ/CtW7diYmKij1OOjroRAT0hKCtWrJDtzz33XKvt/PPPl8c+++yzrbYLLrig1fZymmQA4NSpU622iy++WB779NNPt9pWrVrVapuZmZGPX768n7fIaGX3pvofljo2m2hL3rNPPfVUq23NmjWdH28ayd+o9n4+zl0K4NCc3w83bWZmNgL9TODqY1/r36Ekd5CcIDlx9OjRPk5nZmZz9TOBHwawZc7vlwE4Mv+giNgVEeMRMb5+fesrHDMz61E/X/D9BMDrSL4awG8BvBvA3w6kV+eA7PtA9R32ypUrW23PP/+8fHz2fbeinkOdqzbPPPNMq+2iiy7q/Hj1fbf6Xjw7VlkKweFsDF1jBureBsqCxhdeeOFLddEGrOcJPCJmSH4AwHcBLANwZ0TsH1jPzMzsJfUVYo+IbwP49oD6YmZmBer/d6OZ2cuUJ3Azs0p5Ajczq1Q9ZWbniK5ZIFklpsrAyCroLrnkklbbiRMnWm2vfOUrO/XpXKEyTrJKSEVVV65evbrz40+ePNlqU9d6qVAZJ6dPn261veIVr5CPV/Ub2fXOnsOGw5/Azcwq5QnczKxSnsDNzCrlCdzMrFIOYiZUoAzQS5GWlIar5UlLAj+1BSy7UqXZWbl2ScBSUYHokqVYz1Ul96wa17Fjx+Tj+13DqN+lEyxXz91pZmYv4gnczKxSnsDNzCrlCdzMrFKewM3MKuUslISK3AN6kwW1ScPvf/97+Xi1KXHm4MGDrbatW7d2fvy5ahhZCVkGhcraUcsclGRwnKuyzRTUPauuwdjYWN99UNk8zjgZHn8CNzOrlCdwM7NKeQI3M6tUX9+BkzwI4BSAMwBmImJ8EJ0yM7OFDSKI+ZaI0BGkJUiVIKsd7CNCPv7MmTOttmeffVYeqwKWKjhaEhg9F3QNaqngGwAcP3681ZaVe6t1r5WagpWZrOxfBWiz9eoVdb1LrldNyxHUxlfWzKxS/U7gAeB7JPeQ3DGIDpmZWTf9foVyXUQcIbkBwG6SD0XED+ce0EzsOwDg8ssv7/N0Zmb2gr4+gUfEkebnNIBvALhGHLMrIsYjYrzfZSnNzOwPev4ETvIiAOdFxKnm728H8M8D69kiyyopVdVlyXGqUi0LCKkAXG0By65KNtldt25dqy0LeKrnOHXqVKtNbfxbm5LNsRV1XYD+11/3euDD089XKBsBfIPkC8/zXxHxnYH0yszMFtTzBB4RvwbwhgH2xczMCjiN0MysUp7Azcwq5QnczKxSXg88kWV7PPfcc602lXHyu9/9Tj5eHZuVGqs+qFL8pVCqrK5XloXSdTkDQF8vlXGyFHalLxmDKq/PMnH6zdpxxsnw1HN3mpnZi3gCNzOrlCdwM7NKeQI3M6vUSIOYZ8+eba19vXLlys6Pz9bNXr68PQy13vHMzEznx2dUUKzkXP1SG9dma16r8vIs2NdU1Pb8eBUoU885CFkfFFVGrkq7s/Xb+y0Dz8rTVRBQXcOsX+p9k70/1MbOJ06c6HwuNd6STbtVcDULDpccq8arrkv2/lDv++zeUuNds2ZNqy3bXFtdw0EEzv0J3MysUp7Azcwq5QnczKxSnsDNzCrlCdzMrFIjzUI577zzOmednDx5stXWdWF6oKz8V0WzsywS1f9sM4F+qawAFblW0XBAl+1nfVVLBJRkCClZVoO6tqotW85AvV7ZsV3vGZVdBJRlnDz55JOttrVr13Z+vOpDlsnTdUkHoHtmR0lmSZa5pV7zoqwKcWyWRaLuT3X+7L2slmpQWUeAvg/Ua7Bhwwb5eHVvlGS/ZfwJ3MysUp7Azcwq5QnczKxSC07gJO8kOU1y35y2tSR3k3yk+am/hDUzs6Hp8i36FwB8FsAX57TtBHBfRNxOcmfz+4d76cDx48dle8lO2CrwULJesSqFLwngTU1Ntdqy/qvAyfT0tDxWBURUkCcr11bBp5LSbLVGtyrlB3SgKAvSqHYVaCsJJGfBJ7XutZKVUGcBNEUFLEtK9FXAMguiltwH6r3Qb5JASRBTycr+1Wur+goA69ev73T+7BqqIGS2Bn3X5ReyfQCy51W63rNAh0/gEfFDAPNDqLcAuKv5+10A3tH5jGZmNhC9fge+MSImAaD5qXNnzMxsaIYexCS5g+QEyYmjR48O+3RmZi8bvU7gUyQ3A0DzU3+JCyAidkXEeESMq++szMysN71O4PcC2N78fTuAewbTHTMz64oLRY1JfhnA9QDGAEwB+BiAbwK4G8DlAB4D8K6IaNeKzjM+Ph4TExOdOtbvQvpqXAcPHpTHXnXVVa22LBKsshKyEuZ+qTGUbJKgrmGWXTOM3dezLJKuZdwlGS8lWSQqO0dlJABlr606V5bZoY5Vr1c2LpU5ld0bXV/bLNujJDtFUdkxJVlm2TIHalkIdV1Knrdks5CufQJ0v0qWLiC5JyLG57cvmEYYEbcm/+nGhR5rZmbD40pMM7NKeQI3M6uUJ3Azs0qNdD3wmZmZ1rq42XrJmzZtarVl5bcqGLFq1apWm1qTF+he/gvooJYKUDz11FPy8Sp4kwVplJLASxYEVNSSBiXriasAc0kZurou2blKgrvqGqjgUbZDuDpW7fIOlI1XXduuyxkAOpCbjUEt9aDWkN+4caN8vCqbz4L86rVR1yt7z6n3bUngviSwqfqQlbyrILe6t7I5SgWI1ViBsvH6E7iZWaU8gZuZVcoTuJlZpTyBm5lVaqRBzOXLl7eCltk6zirwkgU+VJBFBSOygFDWB0UFM1TgJKvsy6oTla6b0WaBFzXe7Bp2PTYL1Kn27Fxdnze7ViqQW1IBp2SbIpesqa4Cudk9p/p77NixVltWBamCZVnwKwtOdnlOoP+1w9V9nAXwVHC0JMlA3TPZ49W51GsA6DXV1fUu2Vg6myNKgvT+BG5mVilP4GZmlfIEbmZWKU/gZmaV8gRuZlapkWahKCVrfGdUhLckcl5S6quizKoMPVvv+MSJE53OD+iME1WiX1LCnVHjKrmGTzzxRKtt3bp18tiupcJZBomK3mfRf3W9r7jiilbb5ORk5z5k11tlnGT3t8qAyNaHVlTZvRoroO8vtUZ3ls1UknGixqAybrLML7W0RnZdVH9VRlrJdelXllmirmG2hEbJ+9mfwM3MKuUJ3MysUp7AzcwqteAETvJOktMk981p+zjJ35Lc2/y5ebjdNDOz+boEMb8A4LMAvjiv/TMR8cl+O5CVQJdssqvWw1ZBg+xcKsiRBdpU8EUFLLOyZBU4yQI6KgCm1nHOgh4qsJeVp6vgj1rvOOtrFrBUupbSZ/eAGlcW6FL3waOPPtpqy0rplZK1sEvWdlYB02yNbxUAy4Jy6r5XpeHZa6veXyoICuj3QtdgI6AD59k1VO1qrCXByuy9pMagXu+SpSqy9fpLNlZecJaMiB8CWHDHeTMzG61+vgP/AMkHm69Y2h8LzcxsqHqdwD8H4DUAtgGYBPCp7ECSO0hOkJw4evRoj6czM7P5eprAI2IqIs5ExFkAnwdwzUscuysixiNifP369b3208zM5ulpAie5ec6v7wSwLzvWzMyGY8EsFJJfBnA9gDGShwF8DMD1JLcBCAAHAbyvy8kiolVqmpVAq0h/v2X3WelqyYLxXcudValzdq6S86tS3a6bFgBl0X+VwZE9XkX/s9JslV2iXpvs9VbZElnGisriKHkNVKZDltVQshmBujZddz4H8o0iFHUvqmyLLONFHZstFaF0zRbJlOwUr2T3rMrIKjmXul4l2WvZa1uy6cuCE3hE3Cqa7+h8BjMzGwpXYpqZVcoTuJlZpTyBm5lVauTrgXctLc52rVaefLJdKKqCEVlQbHp6uvO5NmzY0GpTAYqsJFetd1wyVnX9smuqAq7ZsSpgWbKTtipFzwJVqg8qxVS9roAO2mbnUkFEFQDMAl0qyF6yvnQWkFLrur/qVa/qfC5VCp+V+Kvr3TW4m1Fr4AM6uFmyTIK6XlmJvxqXOn92XS6//PJW22OPPSaPVddGLZeRvb/U/Z0lRJQs6+BP4GZmlfIEbmZWKU/gZmaV8gRuZlapkQYxSbYCUKoCENBVSlmgSQUGlSzQddVVV3V6PAAcOnSo1aaCoyVVo1mgSwXbVLBRrREO6HWvSyro1GtT8viStd7Vpsgla5dn9u1rr/Jw7bXXttqyQFfJutvq9coCg+r+OHLkSKstWxtaBVezAJoaW1YprKi1v1UQNaOCzlkQUx2bVZ2qOUIFV7NrqBbXKxmXOn/2eqt7OQtWZnOi4k/gZmaV8gRuZlYpT+BmZpXyBG5mVilP4GZmlRp5Kf18WTS6JNMgW8d4vmzd7Kmpqc7nKtk5XFHjzcaaXZv5srLmkt24VWl3lt2iHDt2rNU2NjbW+fEq06EkUyJz5ZVXttpUCXOWMaNemyw7RvW3ZJmDbH1oRWUqZPd316Uasr6qzIwsU0JlE61bt67VlmVr9HtdVMZN9j4Yxg5h2TVUS1Coex7QmWYZfwI3M6uUJ3Azs0p5Ajczq9SCEzjJLSS/T/IAyf0kb2va15LcTfKR5mf3L0zNzKxvXSKFMwA+FBEPkLwYwB6SuwH8PYD7IuJ2kjsB7ATw4dIOlKyFnQULVeBAld9m5e39bpas1gXOAi9qDFmwsuTaKKrcOisZVwFLFXjJNqEuCVgqJSXMKviT3RuqXDnb3FpR91b2eBXwLFnz+fHHH2+1bdq0ST6+JNCllGyKnAXblK7vJfWeAcoCluralgTuVfA/u7/V66XaSpYIyILOXTdOBzp8Ao+IyYh4oPn7KQAHAFwK4BYAdzWH3QXgHZ3PamZmfSv6DpzkVgBXA7gfwMaImARmJ3kA7a1qzMxsaDpP4CRXAfgagA9GROflskjuIDlBckKt/mVmZr3pNIGTXIHZyftLEfH1pnmK5Obmv28GIDeWjIhdETEeEePDSJw3M3u56pKFQgB3ADgQEZ+e85/uBbC9+ft2APcMvntmZpbpkoVyHYD3APg5yb1N20cB3A7gbpLvBfAYgHcNsmOqXDmL/nfdgT6LfGe7XivqOUqyWFRmR7bgfNflBLLIuTqXulYAMD3d/gfUhg3tsEZWRq5kmSGqXyUZNyUZKyq7RmWWZBkBJZsZqPFmi/are1llnGT3rLpnsvug6zIJWV9LdklXx6rrUpJtkl2DrGy9q5LNSZSSbBF1DbL5rOR6LzhDRMSPAGRX6sbOZzIzs4FyJaaZWaU8gZuZVcoTuJlZpUa+Hvj8L/OzQJcK4JWUQKv1hrPgQEkwQz2HOldJgCULVqqAoSrVVUHB7NjsGqqAZdc+Afq6ZP3qd4mAEtla6fNlfVUBy6y0XK0HnpVWqyCk6kPJmujZe6nruu5ZUK4kWKfWCVdl/6dPn5aPV++F7Bqo9526Btnrpcrus35lAeKu1H3Qdb3/l3zevp/BzMwWhSdwM7NKeQI3M6uUJ3Azs0qNPIg5/4v7kmBGFkhQz6EqDrNAVddAF6A3v1X9GkQwRJ1LBXSyKsJso96uVAVftt5yydrhinoNSoLL2fVWwcKSKkC1bnZJJWim6/XKqhBLAqYqcK2C0VkwXQWoSzbkVYHFrCJYBUyzSmVFJQ+UrBGe9aurrCpb3UclewZk/AnczKxSnsDNzCrlCdzMrFKewM3MKuUJ3MysUiPPQpmvpFQ4K0/vGjnOsiJKyu7VuUrKrVVEPStvVyXnhw8fbrVl65mr7JQsM0X1S5VgZ31V1yDL+lHZDiorIss+UK+NWs8c0ONV91HJkg4ZdR9lWSRq6QKVgZFdb9WvLDtGZROpvpYsyVCyZrU6V6bkeftdD7xfJeMqUVJi70/gZmaV8gRuZlYpT+BmZpXqsqnxFpLfJ3mA5H6StzXtHyf5W5J7mz83D7+7Zmb2gi4RmhkAH4qIB0heDGAPyd3Nf/tMRHxyeN1bPFlgsGtZbxYQKikvn5qaarWVlAWXUP0t2Xx4//79rbbXvva18lgVmCspl1YB4qwsWQUxVcC0JJieBSZVYDHr1+TkZKutpERfXcOsX6q8u2QN+5JgXddlLWwwumxqPAlgsvn7KZIHAFw67I6ZmdlLK/oOnORWAFcDuL9p+gDJB0neSbLbth9mZjYQnSdwkqsAfA3AByPiJIDPAXgNgG2Y/YT+qeRxO0hOkJw4evRo/z02MzMAHSdwkiswO3l/KSK+DgARMRURZyLiLIDPA7hGPTYidkXEeESMr1+/flD9NjN72euShUIAdwA4EBGfntO+ec5h7wSwb/DdMzOzTJcslOsAvAfAz0nubdo+CuBWktsABICDAN43hP4tmiwrQpVcq8h7lm2iyqWzDRk2btzYaivJwFCycylqDFlGQpZxonTdkT3bDV1tGqAWzAf0tVHXIMsaUkoyVrJ+qYwTtaN7VlquXpssQ6ir7HqrPhw7dkweOzY21mpTmUAl96HlumSh/AiAyi/69uC7Y2ZmXbkS08ysUp7Azcwq5QnczKxSi74eeG26BruyIKhqV+s1A3o97n7Lrfst8c+Ccqpc+9ChQ/LYLVu2tNpUGbcKVmaycu2uAbRBrO2szlVSRq7Gm63frvT72mZrj6tlJVSwEtBBfgcsh8efwM3MKuUJ3MysUp7Azcwq5QnczKxSnsDNzCrlLJREFpEv2TW7K5VtAugMBFW2n5VQl2ySoM6lMjNUtklGZZsAumS7pK8lmwaoTQ5UVsQgNh0oeW363fhAXcOS3czVyqAli81lWTtqqQd1z6jNL6ycP4GbmVXKE7iZWaU8gZuZVcoTuJlZpRxJSGQ7dHd1/Phx2a7KpbPgkwrsqaBYSQl1SYl/FshVHn/88Vbbpk2b5LFdA8HZLuuqXDsLAKrrpUrDS4Ko2XUpWY97Zmam1abGla09XlKergKeJQFLdX+pawjkAXkbDn8CNzOrlCdwM7NKeQI3M6tUl02NLyD5Y5I/I7mf5Cea9rUkd5N8pPnpL7/MzEaoSxDzNIAbIuJpkisA/IjkfwP4GwD3RcTtJHcC2Angw0Ps60hllWZd15devXp153Nlm8mqtbfXrl3bauu63jOgg2eADtqWBHLVeFVQLuuDGkPJ5sFZYFGNQQU8SyoDs2uoxpvdRyUVrYoKLGb3Qdeg8dTUlGxXm2tn51KBZxUgLrlnLbfgJ/CY9XTz64rmTwC4BcBdTftdAN4xjA6amZnW6TtwkstI7gUwDWB3RNwPYGNETAJA83PD0HppZmYtnSbwiDgTEdsAXAbgGpJXdj0ByR0kJ0hOqAV0zMysN0VZKBFxHMAPANwEYIrkZgBofk4nj9kVEeMRMV5SPGBmZi+tSxbKepKrm7+vBPBWAA8BuBfA9uaw7QDuGVIfzcxM6BJ63wzgLpLLMDvh3x0R3yL5vwDuJvleAI8BeNcQ+zlyw1qfumsWC6AzTlS2RZYt0jXbI6OyKrIMDJXpkGVgqD6o0uwsU0P1K7sGKltD9bVk9/fs9VLZRNn1VmNQSypkJevq2mRLD3TN5lHZJtnzZs+pXgdnnAzPghN4RDwI4GrR/gSAG4fRKTMzW5grMc3MKuUJ3MysUp7Azcwq5fXAC6ngZknAs2Qd567nz/QbPFJBtZKNc0tK8UtKy0v60LWMvN/XpeRcJUquS8nSAyVKnncY18By/gRuZlYpT+BmZpXyBG5mVilP4GZmlfIEbmZWKU/gZmaV8gRuZlYpT+BmZpXyBG5mVilP4GZmlWK2ZvNQTkYeBfCb5tcxAMdGdvLR8bjq4nHV5eU6risiorWl2Ugn8BedmJyIiPFFOfkQeVx18bjq4nG9mL9CMTOrlCdwM7NKLeYEvmsRzz1MHlddPK66eFxzLNp34GZm1h9/hWJmVqmRT+AkbyL5MMlfkdw56vMPCsk7SU6T3DenbS3J3SQfaX6uWcw+9oLkFpLfJ3mA5H6StzXtVY+N5AUkf0zyZ824PtG0Vz2uF5BcRvKnJL/V/F79uEgeJPlzkntJTjRtS2Fcq0l+leRDzfvszb2Oa6QTOMllAP4NwF8CeD2AW0m+fpR9GKAvALhpXttOAPdFxOsA3Nf8XpsZAB+KiD8FcC2A9zevUe1jOw3ghoh4A4BtAG4ieS3qH9cLbgNwYM7vS2Vcb4mIbXNS7JbCuP4VwHci4k8AvAGzr1tv44qIkf0B8GYA353z+0cAfGSUfRjweLYC2Dfn94cBbG7+vhnAw4vdxwGM8R4Ab1tKYwNwIYAHAPzZUhgXgMuaN/0NAL7VtC2FcR0EMDavrepxAbgEwKNo4o/9jmvUX6FcCuDQnN8PN21LxcaImASA5ueGRe5PX0huBXA1gPuxBMbWfM2wF8A0gN0RsSTGBeBfAPwDgLNz2pbCuALA90juIbmjaat9XH8E4CiA/2i+8vp3khehx3GNegJX25Q7DeYcRHIVgK8B+GBEnFzs/gxCRJyJiG2Y/cR6DckrF7lLfSP5VwCmI2LPYvdlCK6LiDdi9ivX95P8i8Xu0AAsB/BGAJ+LiKsBPIM+vgYa9QR+GMCWOb9fBuDIiPswTFMkNwNA83N6kfvTE5IrMDt5fykivt40L4mxAUBEHAfwA8zGMGof13UA/prkQQBfAXADyf9E/eNCRBxpfk4D+AaAa1D/uA4DONz86w8AvorZCb2ncY16Av8JgNeRfDXJ8wG8G8C9I+7DMN0LYHvz9+2Y/f64KiQJ4A4AByLi03P+U9VjI7me5Orm7ysBvBXAQ6h8XBHxkYi4LCK2Yvb99D8R8XeofFwkLyJ58Qt/B/B2APtQ+bgi4nEAh0j+cdN0I4BfoNdxLcKX+DcD+CWA/wPwj4sdVOhjHF8GMAngecz+X/W9ANZhNpj0SPNz7WL3s4dx/Tlmv9Z6EMDe5s/NtY8NwFUAftqMax+Af2raqx7XvDFejz8EMaseF2a/K/5Z82f/C3NF7eNqxrANwERzL34TwJpex+VKTDOzSrkS08ysUp7Azcwq5QnczKxSnsDNzCrlCdzMrFKewM3MKuUJ3MysUp7Azcwq9f9i5Qih9FVZUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = plt.imread(data_dir+'test_images/contrast/1-5.jpg')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf68123",
   "metadata": {},
   "source": [
    "I also created a txt file with the name of the images and the right numbers. I looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4c4de89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>empty</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file empty   text\n",
       "0  L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...  None     36\n",
       "1  L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...  None     00\n",
       "2  L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...  None     69\n",
       "3  L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...  None     11\n",
       "4  L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...  None   0354\n",
       "5  L:/DATA/ISIS/keras_ocr/test_images/contrast/1-...  None     35"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(data_dir+'test_images/contrast/annotations.txt', header=None, \n",
    "                      names=['file','text'], dtype={'file' : str, 'text' : str})\n",
    "dataset['file'] = data_dir+'test_images/contrast/' + dataset['file']\n",
    "dataset['text'] = dataset['text'].astype(str)\n",
    "dataset.insert(1, 'empty', None)\n",
    "\n",
    "dataset.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9a58e",
   "metadata": {},
   "source": [
    "We now divide the images for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b4801ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset, test_subset = sklearn.model_selection.train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "train_subset.reset_index(inplace=True, drop=True)\n",
    "test_subset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train = []\n",
    "for i in range(len(train_subset)):\n",
    "    train.append(tuple(train_subset.loc[i].to_list()))\n",
    "\n",
    "test = []\n",
    "for i in range(len(test_subset)):\n",
    "    test.append(tuple(test_subset.loc[i].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13628869",
   "metadata": {},
   "source": [
    "We specify that our alphabet is only numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bcd697fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided alphabet does not match pretrained alphabet. Using backbone weights only.\n",
      "Looking for C:\\Users\\mfortier\\.keras-ocr\\crnn_kurapan_notop.h5\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "recognizer = keras_ocr.recognition.Recognizer(alphabet=string.digits)\n",
    "recognizer.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa417e0",
   "metadata": {},
   "source": [
    "We divide the training images in training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2da0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "augmenter = imgaug.augmenters.Sequential([\n",
    "    imgaug.augmenters.GammaContrast(gamma=(0.25, 3.0)),\n",
    "])\n",
    "\n",
    "(training_image_gen, training_steps), (validation_image_gen, validation_steps) = [\n",
    "    (\n",
    "        keras_ocr.datasets.get_recognizer_image_generator(\n",
    "            labels=labels,\n",
    "            height=recognizer.model.input_shape[1],\n",
    "            width=recognizer.model.input_shape[2],\n",
    "            alphabet=recognizer.alphabet,\n",
    "            augmenter=augmenter\n",
    "        ),\n",
    "        len(labels) // batch_size\n",
    "    ) for labels, augmenter in [(train, augmenter), (test, None)]\n",
    "]\n",
    "training_gen, validation_gen = [\n",
    "    recognizer.get_batch_generator(\n",
    "        image_generator=image_generator,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    for image_generator in [training_image_gen, validation_image_gen]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "539a2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 / 288 instances have illegal characters.\n",
      "text: 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181f8742bb0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, text = next(training_image_gen)\n",
    "print('text:', text)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4f41e",
   "metadata": {},
   "source": [
    "Time for the training to begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b408417",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-6939ccc1cf24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'{recognizer_basepath}.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     ]\n\u001b[1;32m----> 7\u001b[1;33m recognizer.training_model.fit(\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtraining_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DevSoftware\\Anaconda38\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recognizer_basepath = os.path.join('L:/DATA/ISIS/keras_ocr/', f'recognizer_{datetime.datetime.now().isoformat()}')\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(restore_best_weights=False, patience=10),\n",
    "    tf.keras.callbacks.CSVLogger(f'{recognizer_basepath}.csv', append=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=f'{recognizer_basepath}.h5')        \n",
    "    ]\n",
    "recognizer.training_model.fit(\n",
    "    training_gen,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    validation_data=validation_gen,\n",
    "    callbacks=callbacks,\n",
    "    epochs=1000,\n",
    "    workers=0,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c995e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepath, _, actual = test[0]\n",
    "predicted = recognizer.recognize(image_filepath)\n",
    "print(f'Predicted: {predicted}, Actual: {actual}')\n",
    "_ = plt.imshow(keras_ocr.tools.read(image_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "def draw_random_subdir(dataDir):\n",
    "    directory_list = os.listdir(dataDir)\n",
    "    directory = directory_list[randrange(len(directory_list))]\n",
    "    subdirectory_list = os.listdir(dataDir + directory + '/')\n",
    "    subdirectory = subdirectory_list[randrange(len(subdirectory_list))]\n",
    "    image_list = os.listdir(dataDir + directory + '/'+subdirectory+'/')\n",
    "    image = image_list[randrange(len(image_list))]    \n",
    "    return directory, subdirectory, image\n",
    "\n",
    "dataDir = 'L:/DATA/ISIS/raw_upload_20230421/'\n",
    "img_list=[]\n",
    "for i in range(3):\n",
    "    directory, subdirectory, image = draw_random_subdir(dataDir)\n",
    "    img_list.append(dataDir + directory + '/' + subdirectory + '/' + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "new_img = []\n",
    "# Change the colors\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "threshold = (85,85,85)\n",
    "\n",
    "for img in img_list :\n",
    "    # Open input image in grayscale mode and get its pixels.\n",
    "    image = Image.open(img).convert(\"LA\")\n",
    "    pixels = image.getdata()\n",
    "    newPixels = []\n",
    "\n",
    "    # Compare each pixel \n",
    "    for pixel in pixels:\n",
    "        if pixel > threshold:\n",
    "            newPixels.append(black)\n",
    "        else:\n",
    "            newPixels.append(white)\n",
    "\n",
    "    # Create and save new image.\n",
    "    image = Image.new(\"RGB\",image.size)\n",
    "    image.putdata(newPixels)\n",
    "    new_img.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline(recognizer=recognizer)\n",
    "prediction_groups = pipeline.recognize(new_img)\n",
    "# plot the text predictions\n",
    "fig, axs = plt.subplots(nrows=len(new_img), figsize=(15, 10))\n",
    "for ax, image, predictions in zip(axs, new_img, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, \n",
    "                                    predictions=predictions, \n",
    "                                    ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img=[]\n",
    "for i,im in enumerate(new_img) :\n",
    "    height, width, _ = im.shape\n",
    "    im = im[int(height-height*0.15):height,0:width]\n",
    "    crop_img.append(im)\n",
    "prediction_groups = pipeline.recognize(crop_img)\n",
    "# plot the text predictions\n",
    "fig, axs = plt.subplots(nrows=len(crop_img), figsize=(15, 7))\n",
    "for ax, image, predictions in zip(axs, crop_img, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, \n",
    "                                    predictions=predictions, \n",
    "                                    ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.model.save_weights(data_dir +'ISIS_reading_contrast.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2d659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
