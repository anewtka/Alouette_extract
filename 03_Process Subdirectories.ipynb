{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16af4dcb",
   "metadata": {},
   "source": [
    "# Process Subdirectories\n",
    "\n",
    "#### Updated: Dec 6, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ef3b7",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495dd95e",
   "metadata": {},
   "source": [
    "Inspect '02_downloaded' folder for fully downloaded subdirectories, move these subdirectories to '03_processing'. Process subdirectories. Record processing performance in a 'process_log'. Then move processed subdirectories to '04_processed' folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8888ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8daa1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e7d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_on_VDI = True\n",
    "\n",
    "rootDir_local = 'C:/Users/rnaidoo/Documents/Projects_data/Alouette_I/' #C: is not persistent on VDI\n",
    "rootDir_U = 'U:/Data_Science/Projects_data/Alouette_I/'\n",
    "downloadedDir = rootDir_local + '02_downloaded/'\n",
    "processingDir = rootDir_local + '03_processing/'\n",
    "if process_on_VDI:\n",
    "    processedDir = rootDir_U + '04_processed/' \n",
    "    resultDir = rootDir_U + '05_result/' \n",
    "    logDir = '//scientific/L-MP-Data/Massive files/Python/rnaidoo/Alouette_I/' #DO NOT CHANGE\n",
    "    move_to_U = True\n",
    "else:\n",
    "    processedDir = rootDir_local + '04_processed/' \n",
    "    resultDir = rootDir_local + '05_result/' \n",
    "    logDir = resultDir\n",
    "    move_to_U = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a9e9f0",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037cd95",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a03203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(old_dir, new_dir, roll, subdir, copy_to_other_drive=False):\n",
    "    oldDir = old_dir + roll + '/' + subdir + '/'\n",
    "    newDir = new_dir + roll + '/' + subdir + '/'\n",
    "    os.makedirs(newDir, exist_ok=True)\n",
    "    \n",
    "    if copy_to_other_drive:\n",
    "        for file in os.listdir(oldDir):\n",
    "            shutil.copyfile(oldDir+file, newDir+file)\n",
    "    else:\n",
    "        for file in os.listdir(oldDir):\n",
    "            os.rename(oldDir+file, newDir+file)\n",
    "    \n",
    "    shutil.rmtree(old_dir + roll + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebbb9e",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274a9f4",
   "metadata": {},
   "source": [
    "#### Process new fully downloaded subdirectories:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a042f",
   "metadata": {},
   "source": [
    "Move one fully downloaded subdirectory from '02_downloaded' to '03_processing', process, then move images to '04_processing' - do this one subdirectory at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d875619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R014207821/3342-A38/ subdirectory...\n",
      "Processing time for subdirectory: 5.7 min\n",
      "Moving images to '04_processed'\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame()\n",
    "for roll in os.listdir(downloadedDir):\n",
    "    if 'R' in roll:\n",
    "        for subdirectory in os.listdir(downloadedDir + roll):\n",
    "            start = time.time()\n",
    "            subdir_path_end = roll + '/' + subdirectory + '/'\n",
    "            \n",
    "            #Move to '03_processing'\n",
    "            move_images(old_dir=downloadedDir, new_dir=processingDir, roll=roll, subdir=subdirectory)\n",
    "            \n",
    "            #Process\n",
    "            print('Processing ' + subdir_path_end + ' subdirectory...')\n",
    "            !python scan2data/user_input.py $processingDir $resultDir\n",
    "\n",
    "            #Consolidate results\n",
    "            df_dot = pd.read_csv(resultDir + 'df_dot.csv')\n",
    "            n_dot = len(df_dot)\n",
    "            df_dot['processed_image_class'] = 'dot'\n",
    "            \n",
    "            df_num = pd.read_csv(resultDir + 'df_num.csv')\n",
    "            n_num = len(df_num)\n",
    "            df_num['processed_image_class'] = 'num'\n",
    "            \n",
    "            df_loss = pd.read_csv(resultDir + 'df_loss.csv')\n",
    "            n_loss = len(df_loss)\n",
    "            df_loss['processed_image_class'] = 'loss'\n",
    "            \n",
    "            df_outlier = pd.read_csv(resultDir + 'df_outlier.csv')\n",
    "            n_outlier = len(df_outlier)\n",
    "            df_outlier['processed_image_class'] = 'outlier'\n",
    "            \n",
    "            df_tot = pd.concat([df_dot, df_num, df_loss, df_outlier])\n",
    "            df_tot['Roll'] = roll\n",
    "            df_tot['Subdirectory'] = subdirectory\n",
    "            df_tot = df_tot.drop(columns=['file_name', 'mapped_coord', 'subdir_name', 'raw', 'ionogram', 'raw_metadata', \n",
    "                                          'trimmed_metadata', 'padded', 'dilated_metadata'], errors='ignore')\n",
    "            df_tot.to_csv(resultDir + 'result-' + roll + '_' + subdirectory + '.csv', index=False)\n",
    "            \n",
    "            os.remove(resultDir + 'df_dot.csv')\n",
    "            os.remove(resultDir + 'df_num.csv')\n",
    "            os.remove(resultDir + 'df_loss.csv')\n",
    "            os.remove(resultDir + 'df_outlier.csv')\n",
    "            \n",
    "            end = time.time()\n",
    "            t = end - start\n",
    "            print('Processing time for subdirectory: ' + str(round(t/60, 1)) + ' min')\n",
    "            \n",
    "            #Record performance\n",
    "            df_result_ = pd.DataFrame({\n",
    "                'Roll': roll,\n",
    "                'Subdirectory': subdirectory,\n",
    "                'Images_processed': n_dot + n_num + n_loss + n_outlier,\n",
    "                'Images_dot': n_dot,\n",
    "                'Images_num': n_num,\n",
    "                'Images_loss': n_loss,\n",
    "                'Images_outlier': n_outlier,\n",
    "                'Process_time': t,\n",
    "                'Process_timestamp': datetime.fromtimestamp(end)\n",
    "            }, index=[0])\n",
    "            df_result = pd.concat([df_result, df_result_], axis=0, ignore_index=True)  \n",
    "            \n",
    "            #Move to '04_processed'\n",
    "            print(\"Moving images to '04_processed'\")\n",
    "            move_images(old_dir=processingDir, new_dir=processedDir, roll=roll, subdir=subdirectory, copy_to_other_drive=move_to_U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3d9a8",
   "metadata": {},
   "source": [
    "Add to results to 'process_log':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a63bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(logDir + 'process_log.csv'):\n",
    "    df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "    df_update = pd.concat([df_log, df_result], axis=0, ignore_index=True)\n",
    "    df_update.to_csv(logDir + 'process_log.csv', index=False)\n",
    "else:\n",
    "    if len(df_result) > 0:\n",
    "        df_result.to_csv(logDir + 'process_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b240f65",
   "metadata": {},
   "source": [
    "Backup 'process_log' (10% of the time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc63d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "if randrange(10) == 7:\n",
    "    df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "    datetime_str = datetime.now().strftime(\"%Y%m%d_%Hh%M\")\n",
    "    os.makedirs(logDir + 'backups/', exist_ok=True)\n",
    "    df_log.to_csv(logDir + 'backups/' + 'process_log-' + datetime_str + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d89f7",
   "metadata": {},
   "source": [
    "Processing on CSA laptop (C:) (Intel Core i7-10610U CPU @ 1.80 GHz, 2.30 GHz, 16 GB RAM) --> 18.4 min <br>\n",
    "Processing on VDI HP (C:) (Intel Xeon Gold 6248 CPU @ 2.50GHz, 2.49 GHz  (2 processors), 64 GB RAM) --> 18.1 min <br>\n",
    "<br>\n",
    "- Upon inspection of computer performance, processing appears to be much more CPU-intensive rather than RAM-intensive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
